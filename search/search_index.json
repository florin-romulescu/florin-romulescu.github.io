{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>Author: Florin Romulescu</p> <p>Repository: florin-romulescu/Final-Year-Project</p>"},{"location":"#introduction","title":"Introduction","text":"<p>This project will represent my final year project for my Computer Science and Engineering degree at Politehnica University of Bucharest.</p>"},{"location":"#project-description","title":"Project Description","text":"<p>This project is an application that analyzes concept drifting in research papers.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Crawl the web for research papers</li> <li>Analyze the research papers for concept drifting</li> </ul>"},{"location":"crawler/crawler/","title":"Crawler Service Documentation","text":""},{"location":"crawler/crawler/#overview","title":"Overview","text":"<p>This module provides services for crawling and fetching publication data from various sources, specifically integrating with the Semantic Scholar API. The core functionality revolves around retrieving metadata for academic papers based on search queries and unique identifiers.</p>"},{"location":"crawler/crawler/#classes","title":"Classes","text":""},{"location":"crawler/crawler/#1-crawlerservice-abstract-base-class","title":"1. <code>CrawlerService</code> (Abstract Base Class)","text":""},{"location":"crawler/crawler/#description","title":"Description","text":"<p><code>CrawlerService</code> is an abstract base class that defines a common interface for web crawling services.</p>"},{"location":"crawler/crawler/#methods","title":"Methods","text":"<ul> <li><code>crawl(self, query: str) -&gt; Publication</code></li> <li>Abstract method that must be implemented by subclasses.</li> <li>It should accept a search query as input and return a <code>Publication</code> object.</li> <li><code>get_publication(self, paper_id: str) -&gt; Publication</code></li> <li>Abstract method that must be implemented by subclasses.</li> <li>It should accept a paper ID as input and return a <code>Publication</code> object.</li> </ul>"},{"location":"crawler/crawler/#2-semanticcrawlerservice","title":"2. <code>SemanticCrawlerService</code>","text":""},{"location":"crawler/crawler/#description_1","title":"Description","text":"<p><code>SemanticCrawlerService</code> is a concrete implementation of <code>CrawlerService</code> that interacts with the Semantic Scholar API to fetch publication details.</p>"},{"location":"crawler/crawler/#methods_1","title":"Methods","text":""},{"location":"crawler/crawler/#crawlself-query-str-publication","title":"<code>crawl(self, query: str) -&gt; Publication</code>","text":"<ul> <li> <p>Purpose:</p> </li> <li> <p>Searches for a publication based on a given query string using the Semantic Scholar API.</p> </li> <li> <p>Retrieves the first matching paper\u2019s ID and fetches its full details.</p> </li> <li> <p>Process:</p> </li> <li> <p>Sends a GET request to the Semantic Scholar search API with the query.</p> </li> <li>Handles rate limiting (<code>HTTP 429</code>) by retrying with a short delay.</li> <li>Extracts the <code>paperId</code> from the response.</li> <li> <p>Calls <code>get_publication(paper_id)</code> to fetch complete details.</p> </li> <li> <p>Parameters:</p> </li> <li> <p><code>query</code> (<code>str</code>): The search term used to find publications.</p> </li> <li> <p>Returns:</p> </li> <li><code>Publication</code>: A <code>Publication</code> object containing metadata of the first matching paper.</li> <li><code>None</code>: If no results are found.</li> </ul>"},{"location":"crawler/crawler/#get_publicationself-paper_id-str-publication","title":"<code>get_publication(self, paper_id: str) -&gt; Publication</code>","text":"<ul> <li> <p>Purpose:</p> </li> <li> <p>Fetches detailed metadata of a publication using its paper ID from the Semantic Scholar API.</p> </li> <li> <p>Process:</p> </li> <li> <p>Constructs the API request URL with specific metadata fields.</p> </li> <li>Sends a GET request with API authentication.</li> <li>Handles rate limiting (<code>HTTP 429</code>) with retries.</li> <li> <p>Parses the response JSON and constructs a <code>SemanticPublication</code> object.</p> </li> <li> <p>Parameters:</p> </li> <li> <p><code>paper_id</code> (<code>str</code>): Unique identifier of the paper from Semantic Scholar.</p> </li> <li> <p>Returns:</p> </li> <li><code>SemanticPublication</code>: A detailed representation of the paper, including title, authors, citations, fields of study, and availability.</li> </ul>"},{"location":"crawler/crawler/#data-models-used","title":"Data Models Used","text":"<ul> <li><code>Publication</code>: A general class representing publication details.</li> <li><code>SemanticPublication</code>: A specialized subclass with additional Semantic Scholar metadata.</li> <li><code>Bib</code>: A bibliographic metadata container (title, authors, year, venue, abstract).</li> <li><code>Author</code>: Represents an author with a name and unique identifier.</li> </ul>"},{"location":"crawler/crawler/#dependencies","title":"Dependencies","text":"<ul> <li><code>requests</code> (for API communication)</li> <li><code>time</code> (for handling rate limits)</li> <li><code>abc</code> (for defining abstract classes)</li> <li><code>crawler.config</code> (for API key and configuration)</li> <li><code>crawler.publication</code> (for publication data models)</li> </ul>"},{"location":"crawler/crawler/#usage-example","title":"Usage Example","text":"<pre><code>from crawler.semantic_crawler import SemanticCrawlerService\n\ncrawler = SemanticCrawlerService()\npublication = crawler.crawl(\"Machine Learning in Healthcare\")\n\nif publication:\n    print(f\"Title: {publication.bib.title}\")\n    print(f\"Authors: {[author.name for author in publication.bib.authors]}\")\n    print(f\"Year: {publication.bib.pub_year}\")\n    print(f\"URL: {publication.url}\")\nelse:\n    print(\"No publication found.\")\n</code></pre>"},{"location":"crawler/crawler/#notes","title":"Notes","text":"<ul> <li>Ensure a valid API key is provided in <code>crawler.config</code>.</li> <li>The Semantic Scholar API has request limits; the service implements retry logic for rate-limited requests (<code>429 Too Many Requests</code>).</li> <li>The crawler only returns the first matching result from a search query.</li> </ul>"},{"location":"crawler/publication/","title":"Publication Models Documentation","text":"<p>This documentation provides an overview of the models defined for handling publication data. The module leverages Pydantic to enforce data validation and management through Python classes.</p>"},{"location":"crawler/publication/#overview","title":"Overview","text":"<p>The file defines models related to publications. It includes:</p> <ul> <li>Bib: Represents basic bibliographic information.</li> <li>Publication: A base model for publications that provides accessors to bibliographic details.</li> <li>SemanticPublication: A subclass of <code>Publication</code> that includes additional semantic information, such as citation counts and access URLs.</li> </ul>"},{"location":"crawler/publication/#models","title":"Models","text":""},{"location":"crawler/publication/#1-bib-model","title":"1. Bib Model","text":"<p>The <code>Bib</code> model holds essential bibliographic details about a publication.</p>"},{"location":"crawler/publication/#attributes","title":"Attributes","text":"<ul> <li>title (<code>str</code>): The title of the publication.</li> <li>author (<code>List[str]</code>): A list of authors.</li> <li>pub_year (<code>str</code>): The publication year.</li> <li>venue (<code>str</code>): The venue or conference where the work was published.</li> <li>abstract (<code>str</code>): A short summary or abstract of the publication.</li> </ul>"},{"location":"crawler/publication/#example-usage","title":"Example Usage","text":"<pre><code>from pydantic import BaseModel\nfrom typing import List\n\n# Example instance of the Bib model\nbib_entry = Bib(\n    title=\"Deep Learning\",\n    author=[\"Ian Goodfellow\", \"Yoshua Bengio\", \"Aaron Courville\"],\n    pub_year=\"2016\",\n    venue=\"MIT Press\",\n    abstract=\"A comprehensive introduction to deep learning.\"\n)\n</code></pre>"},{"location":"crawler/publication/#2-publication-model","title":"2. Publication Model","text":"<p>The <code>Publication</code> model encapsulates a publication by holding a <code>Bib</code> instance. It provides convenient property methods to access key bibliographic information.</p>"},{"location":"crawler/publication/#attributes_1","title":"Attributes","text":"<ul> <li>bib (<code>Bib</code>): An instance of the <code>Bib</code> model containing bibliographic details.</li> </ul>"},{"location":"crawler/publication/#properties","title":"Properties","text":"<ul> <li>title (<code>str</code>): Returns the publication's title.</li> <li>authors (<code>List[str]</code>): Returns the list of authors.</li> <li>year (<code>str</code>): Returns the publication year.</li> <li>venue (<code>str</code>): Returns the venue of the publication.</li> <li>abstract (<code>str</code>): Returns the abstract of the publication.</li> <li>citations (<code>Optional[int]</code>): Returns the number of citations. This is meant to be implemented by subclasses and defaults to <code>None</code>.</li> <li>pdf_url (<code>Optional[HttpUrl]</code>): Returns the URL to the PDF if available. Meant to be implemented by subclasses and defaults to <code>None</code>.</li> <li>publication_url (<code>Optional[HttpUrl]</code>): Returns the URL to the publication page. Meant to be implemented by subclasses and defaults to <code>None</code>.</li> <li>keywords (<code>List[str]</code>): Returns the keywords associated with the publication. Defaults to an empty list.</li> </ul>"},{"location":"crawler/publication/#example-usage_1","title":"Example Usage","text":"<pre><code># Create a Publication instance using the previously defined Bib entry.\npublication = Publication(bib=bib_entry)\n\nprint(\"Title:\", publication.title)\nprint(\"Authors:\", publication.authors)\nprint(\"Year:\", publication.year)\nprint(\"Venue:\", publication.venue)\nprint(\"Abstract:\", publication.abstract)\n# Since citations, pdf_url, and publication_url are not implemented in Publication,\n# they will return their default values.\nprint(\"Citations:\", publication.citations)\nprint(\"PDF URL:\", publication.pdf_url)\nprint(\"Publication URL:\", publication.publication_url)\nprint(\"Keywords:\", publication.keywords)\n</code></pre>"},{"location":"crawler/publication/#3-semanticpublication-model","title":"3. SemanticPublication Model","text":"<p>The <code>SemanticPublication</code> model extends <code>Publication</code> with additional semantic and metadata information, typically sourced from services like Semantic Scholar.</p>"},{"location":"crawler/publication/#additional-attributes","title":"Additional Attributes","text":"<ul> <li>paper_id (<code>str</code>): Unique identifier for the paper.</li> <li>url (<code>Optional[HttpUrl]</code>): URL of the publication page.</li> <li>citation_count (<code>Optional[int]</code>): The total number of citations.</li> <li>influential_citation_count (<code>Optional[int]</code>): The number of influential citations.</li> <li>references (<code>Optional[List[dict]]</code>): A list of references cited in the publication.</li> <li>fields_of_study (<code>Optional[List[str]]</code>): Keywords or fields of study associated with the publication.</li> <li>is_open_access (<code>Optional[bool]</code>): Indicates if the publication is open access.</li> <li>open_access_pdf (<code>Optional[HttpUrl]</code>): URL to the open-access PDF version of the publication.</li> </ul>"},{"location":"crawler/publication/#overridden-properties","title":"Overridden Properties","text":"<ul> <li>citations (<code>int</code>): Returns the number of citations from <code>citation_count</code>.</li> <li>pdf_url (<code>Optional[HttpUrl]</code>): Returns the URL to the open-access PDF from <code>open_access_pdf</code>.</li> <li>publication_url (<code>HttpUrl</code>): Returns the publication page URL from <code>url</code>.</li> <li>keywords (<code>List[str]</code>): Returns the list of fields of study from <code>fields_of_study</code>.</li> </ul>"},{"location":"crawler/publication/#example-usage_2","title":"Example Usage","text":"<pre><code>from pydantic import HttpUrl\n\n# Create an instance of SemanticPublication using the same Bib entry\nsemantic_pub = SemanticPublication(\n    bib=bib_entry,\n    paper_id=\"123456\",\n    url=\"https://example.com/publication\",\n    citation_count=50,\n    influential_citation_count=10,\n    references=[{\"id\": \"ref1\"}, {\"id\": \"ref2\"}],\n    fields_of_study=[\"Computer Science\", \"Artificial Intelligence\"],\n    is_open_access=True,\n    open_access_pdf=\"https://example.com/publication.pdf\"\n)\n\nprint(\"Title:\", semantic_pub.title)\nprint(\"Authors:\", semantic_pub.authors)\nprint(\"Citations:\", semantic_pub.citations)\nprint(\"PDF URL:\", semantic_pub.pdf_url)\nprint(\"Publication URL:\", semantic_pub.publication_url)\nprint(\"Keywords:\", semantic_pub.keywords)\n</code></pre>"},{"location":"crawler/publication/#conclusion","title":"Conclusion","text":"<p>This module provides a structured way to handle publication data using Pydantic models. The <code>Bib</code> class is used for storing fundamental bibliographic information, while the <code>Publication</code> class and its subclass <code>SemanticPublication</code> add layers of functionality, making it easier to work with both basic and enriched publication metadata.</p> <p>Feel free to extend these models further to suit your application needs.</p>"}]}